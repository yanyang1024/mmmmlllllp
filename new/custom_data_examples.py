"""
è‡ªå®šä¹‰æ•°æ®é›†ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•å°†ä¸åŒæ ¼å¼çš„æ•°æ®è½¬æ¢ä¸ºMLPé¡¹ç›®å¯ç”¨çš„æ ¼å¼
"""

import numpy as np
import pandas as pd
import yaml
from loguru import logger
from typing import Tuple, List, Dict, Any

from data_processor import DataProcessor
from mlp_model import create_model_from_config
from trainer import MLPTrainer
from evaluator import ModelEvaluator


def example_1_numpy_arrays():
    """
    ç¤ºä¾‹1: ä»NumPyæ•°ç»„åˆ›å»ºæ•°æ®é›†
    é€‚ç”¨åœºæ™¯: å·²æœ‰å¤„ç†å¥½çš„æ•°å€¼æ•°æ®
    """
    print("\n" + "="*60)
    print("ç¤ºä¾‹1: ä½¿ç”¨NumPyæ•°ç»„æ•°æ®")
    print("="*60)
    
    # æ¨¡æ‹Ÿæˆ¿ä»·é¢„æµ‹æ•°æ®
    # è¾“å…¥ç‰¹å¾: é¢ç§¯, æˆ¿é—´æ•°, æ¥¼å±‚, å»ºé€ å¹´ä»½, è·ç¦»å¸‚ä¸­å¿ƒè·ç¦»
    np.random.seed(42)
    n_samples = 1000
    
    # ç”Ÿæˆè¾“å…¥ç‰¹å¾ (n_samples, 5)
    area = np.random.normal(100, 30, n_samples)  # é¢ç§¯ (å¹³æ–¹ç±³)
    rooms = np.random.randint(1, 6, n_samples)   # æˆ¿é—´æ•°
    floor = np.random.randint(1, 21, n_samples)  # æ¥¼å±‚
    year = np.random.randint(1990, 2024, n_samples)  # å»ºé€ å¹´ä»½
    distance = np.random.exponential(5, n_samples)   # è·ç¦»å¸‚ä¸­å¿ƒ (å…¬é‡Œ)
    
    X = np.column_stack([area, rooms, floor, year, distance]).astype(np.float32)
    
    # ç”Ÿæˆç›®æ ‡å€¼ (n_samples, 2)
    # ç›®æ ‡1: æˆ¿ä»· (ä¸‡å…ƒ), ç›®æ ‡2: ç§Ÿé‡‘ (å…ƒ/æœˆ)
    price = (area * 0.8 + rooms * 5 + (2024 - year) * 0.1 - distance * 2 + 
             np.random.normal(0, 5, n_samples))
    rent = price * 50 + np.random.normal(0, 200, n_samples)
    
    y = np.column_stack([price, rent]).astype(np.float32)
    
    print(f"æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
    print(f"è¾“å…¥ç‰¹å¾: é¢ç§¯, æˆ¿é—´æ•°, æ¥¼å±‚, å»ºé€ å¹´ä»½, è·ç¦»å¸‚ä¸­å¿ƒ")
    print(f"è¾“å‡ºç›®æ ‡: æˆ¿ä»·(ä¸‡å…ƒ), ç§Ÿé‡‘(å…ƒ/æœˆ)")
    print(f"æ•°æ®æ ·ä¾‹:")
    print(f"  X[0]: {X[0]}")
    print(f"  y[0]: {y[0]}")
    
    # ä½¿ç”¨æ•°æ®è®­ç»ƒæ¨¡å‹
    config = load_config()
    config['training']['epochs'] = 20  # å¿«é€Ÿæ¼”ç¤º
    
    success = train_with_custom_data(X, y, config, "æˆ¿ä»·é¢„æµ‹æ¨¡å‹")
    
    return X, y, success


def example_2_pandas_dataframe():
    """
    ç¤ºä¾‹2: ä»Pandas DataFrameåˆ›å»ºæ•°æ®é›†
    é€‚ç”¨åœºæ™¯: ç»“æ„åŒ–æ•°æ®ï¼Œéœ€è¦ç‰¹å¾é€‰æ‹©å’Œé¢„å¤„ç†
    """
    print("\n" + "="*60)
    print("ç¤ºä¾‹2: ä½¿ç”¨Pandas DataFrameæ•°æ®")
    print("="*60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„å­¦ç”Ÿæˆç»©é¢„æµ‹æ•°æ®
    np.random.seed(42)
    n_samples = 800
    
    # åˆ›å»ºDataFrame
    data = {
        'study_hours': np.random.normal(6, 2, n_samples),      # å­¦ä¹ æ—¶é—´
        'sleep_hours': np.random.normal(7, 1, n_samples),      # ç¡çœ æ—¶é—´
        'exercise_hours': np.random.normal(1, 0.5, n_samples), # è¿åŠ¨æ—¶é—´
        'family_income': np.random.normal(50000, 15000, n_samples), # å®¶åº­æ”¶å…¥
        'previous_score': np.random.normal(75, 10, n_samples), # ä¹‹å‰æˆç»©
        'attendance_rate': np.random.uniform(0.7, 1.0, n_samples), # å‡ºå‹¤ç‡
        'age': np.random.randint(16, 20, n_samples),           # å¹´é¾„
        'gender': np.random.choice([0, 1], n_samples),         # æ€§åˆ« (0:å¥³, 1:ç”·)
        
        # ç›®æ ‡å˜é‡
        'math_score': 0,    # æ•°å­¦æˆç»©
        'english_score': 0, # è‹±è¯­æˆç»©
        'science_score': 0  # ç§‘å­¦æˆç»©
    }
    
    df = pd.DataFrame(data)
    
    # ç”Ÿæˆç›®æ ‡å˜é‡ (åŸºäºè¾“å…¥ç‰¹å¾çš„å¤æ‚å…³ç³»)
    df['math_score'] = (
        df['study_hours'] * 3 + 
        df['previous_score'] * 0.6 + 
        df['attendance_rate'] * 20 + 
        np.random.normal(0, 5, n_samples)
    ).clip(0, 100)
    
    df['english_score'] = (
        df['study_hours'] * 2.5 + 
        df['previous_score'] * 0.7 + 
        df['sleep_hours'] * 2 + 
        np.random.normal(0, 4, n_samples)
    ).clip(0, 100)
    
    df['science_score'] = (
        df['study_hours'] * 3.5 + 
        df['previous_score'] * 0.5 + 
        df['exercise_hours'] * 3 + 
        np.random.normal(0, 6, n_samples)
    ).clip(0, 100)
    
    print(f"DataFrameå½¢çŠ¶: {df.shape}")
    print(f"åˆ—å: {list(df.columns)}")
    print(f"æ•°æ®æ ·ä¾‹:")
    print(df.head(3))
    
    # æå–ç‰¹å¾å’Œç›®æ ‡
    feature_columns = ['study_hours', 'sleep_hours', 'exercise_hours', 
                      'family_income', 'previous_score', 'attendance_rate', 
                      'age', 'gender']
    target_columns = ['math_score', 'english_score', 'science_score']
    
    X = df[feature_columns].values.astype(np.float32)
    y = df[target_columns].values.astype(np.float32)
    
    print(f"\næå–åæ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
    print(f"ç‰¹å¾åˆ—: {feature_columns}")
    print(f"ç›®æ ‡åˆ—: {target_columns}")
    
    # ä½¿ç”¨æ•°æ®è®­ç»ƒæ¨¡å‹
    config = load_config()
    config['training']['epochs'] = 20
    
    success = train_with_custom_data(X, y, config, "å­¦ç”Ÿæˆç»©é¢„æµ‹æ¨¡å‹")
    
    return X, y, success


def example_3_csv_file():
    """
    ç¤ºä¾‹3: ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®
    é€‚ç”¨åœºæ™¯: å¤–éƒ¨æ•°æ®æ–‡ä»¶
    """
    print("\n" + "="*60)
    print("ç¤ºä¾‹3: ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®")
    print("="*60)
    
    # åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶
    csv_filename = "sample_data.csv"
    
    # ç”Ÿæˆè‚¡ç¥¨ä»·æ ¼é¢„æµ‹æ•°æ®
    np.random.seed(42)
    n_samples = 600
    
    # æŠ€æœ¯æŒ‡æ ‡ä½œä¸ºè¾“å…¥ç‰¹å¾
    data = {
        'open_price': np.random.uniform(50, 150, n_samples),
        'high_price': np.random.uniform(55, 155, n_samples),
        'low_price': np.random.uniform(45, 145, n_samples),
        'volume': np.random.uniform(1000000, 10000000, n_samples),
        'rsi': np.random.uniform(20, 80, n_samples),          # RSIæŒ‡æ ‡
        'macd': np.random.uniform(-2, 2, n_samples),          # MACDæŒ‡æ ‡
        'bollinger_upper': np.random.uniform(60, 160, n_samples),
        'bollinger_lower': np.random.uniform(40, 140, n_samples),
        'moving_avg_5': np.random.uniform(52, 152, n_samples),
        'moving_avg_20': np.random.uniform(51, 151, n_samples),
    }
    
    df = pd.DataFrame(data)
    
    # ç”Ÿæˆç›®æ ‡å˜é‡
    # ç›®æ ‡1: ä¸‹ä¸€æ—¥æ”¶ç›˜ä»·, ç›®æ ‡2: ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”
    df['next_close'] = (
        df['open_price'] * 0.7 + 
        df['moving_avg_5'] * 0.2 + 
        df['rsi'] * 0.3 + 
        np.random.normal(0, 3, n_samples)
    )
    
    df['price_change_pct'] = (
        (df['next_close'] - df['open_price']) / df['open_price'] * 100
    )
    
    # ä¿å­˜åˆ°CSV
    df.to_csv(csv_filename, index=False)
    print(f"å·²åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶: {csv_filename}")
    print(f"æ–‡ä»¶åŒ…å« {len(df)} è¡Œæ•°æ®ï¼Œ{len(df.columns)} åˆ—")
    print(f"åˆ—å: {list(df.columns)}")
    
    # ä»CSVåŠ è½½æ•°æ®
    feature_columns = ['open_price', 'high_price', 'low_price', 'volume', 
                      'rsi', 'macd', 'bollinger_upper', 'bollinger_lower',
                      'moving_avg_5', 'moving_avg_20']
    target_columns = ['next_close', 'price_change_pct']
    
    # ä½¿ç”¨DataProcessorçš„CSVåŠ è½½åŠŸèƒ½
    config = load_config()
    config['training']['epochs'] = 20
    
    processor = DataProcessor(config)
    processor.load_data_from_csv(csv_filename, target_columns, feature_columns)
    
    print(f"\nä»CSVåŠ è½½çš„æ•°æ®å½¢çŠ¶: X={processor.X_raw.shape}, y={processor.y_raw.shape}")
    print(f"è¾“å…¥ç»´åº¦: {processor.input_dim}, è¾“å‡ºç»´åº¦: {processor.output_dim}")
    
    # è®­ç»ƒæ¨¡å‹
    success = train_with_processor(processor, config, "è‚¡ç¥¨ä»·æ ¼é¢„æµ‹æ¨¡å‹")
    
    return processor.X_raw, processor.y_raw, success


def example_4_time_series_data():
    """
    ç¤ºä¾‹4: æ—¶é—´åºåˆ—æ•°æ®è½¬æ¢
    é€‚ç”¨åœºæ™¯: æ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡
    """
    print("\n" + "="*60)
    print("ç¤ºä¾‹4: æ—¶é—´åºåˆ—æ•°æ®è½¬æ¢")
    print("="*60)
    
    # ç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ® (å¦‚ä¼ æ„Ÿå™¨æ•°æ®)
    np.random.seed(42)
    n_timesteps = 1000
    
    # ç”Ÿæˆå¤šä¸ªä¼ æ„Ÿå™¨çš„æ—¶é—´åºåˆ—
    time = np.arange(n_timesteps)
    
    # ä¼ æ„Ÿå™¨1: æ¸©åº¦ (æœ‰å­£èŠ‚æ€§)
    temp = 20 + 10 * np.sin(2 * np.pi * time / 365) + np.random.normal(0, 2, n_timesteps)
    
    # ä¼ æ„Ÿå™¨2: æ¹¿åº¦ (ä¸æ¸©åº¦ç›¸å…³)
    humidity = 60 - 0.5 * temp + np.random.normal(0, 5, n_timesteps)
    
    # ä¼ æ„Ÿå™¨3: å‹åŠ› (æœ‰è¶‹åŠ¿)
    pressure = 1013 + 0.01 * time + np.random.normal(0, 3, n_timesteps)
    
    # ä¼ æ„Ÿå™¨4: é£é€Ÿ
    wind_speed = 5 + 3 * np.sin(2 * np.pi * time / 24) + np.random.normal(0, 1, n_timesteps)
    
    print(f"åŸå§‹æ—¶é—´åºåˆ—é•¿åº¦: {n_timesteps}")
    print(f"ä¼ æ„Ÿå™¨æ•°é‡: 4 (æ¸©åº¦, æ¹¿åº¦, å‹åŠ›, é£é€Ÿ)")
    
    # è½¬æ¢ä¸ºç›‘ç£å­¦ä¹ é—®é¢˜
    # ä½¿ç”¨è¿‡å»Nä¸ªæ—¶é—´æ­¥é¢„æµ‹æœªæ¥Mä¸ªæ—¶é—´æ­¥
    lookback = 24  # ä½¿ç”¨è¿‡å»24å°æ—¶çš„æ•°æ®
    forecast = 6   # é¢„æµ‹æœªæ¥6å°æ—¶
    
    X_list = []
    y_list = []
    
    for i in range(lookback, n_timesteps - forecast):
        # è¾“å…¥: è¿‡å»24å°æ—¶çš„4ä¸ªä¼ æ„Ÿå™¨æ•°æ® (24 * 4 = 96 ä¸ªç‰¹å¾)
        x_window = np.column_stack([
            temp[i-lookback:i],
            humidity[i-lookback:i], 
            pressure[i-lookback:i],
            wind_speed[i-lookback:i]
        ]).flatten()
        
        # è¾“å‡º: æœªæ¥6å°æ—¶çš„æ¸©åº¦å’Œæ¹¿åº¦ (6 * 2 = 12 ä¸ªç›®æ ‡)
        y_window = np.column_stack([
            temp[i:i+forecast],
            humidity[i:i+forecast]
        ]).flatten()
        
        X_list.append(x_window)
        y_list.append(y_window)
    
    X = np.array(X_list, dtype=np.float32)
    y = np.array(y_list, dtype=np.float32)
    
    print(f"\nè½¬æ¢åæ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
    print(f"è¾“å…¥ç‰¹å¾: è¿‡å»{lookback}å°æ—¶çš„4ä¸ªä¼ æ„Ÿå™¨æ•°æ® ({lookback * 4}ç»´)")
    print(f"è¾“å‡ºç›®æ ‡: æœªæ¥{forecast}å°æ—¶çš„æ¸©åº¦å’Œæ¹¿åº¦ ({forecast * 2}ç»´)")
    print(f"æ ·æœ¬æ•°é‡: {len(X)}")
    
    # ä½¿ç”¨æ•°æ®è®­ç»ƒæ¨¡å‹
    config = load_config()
    config['training']['epochs'] = 20
    config['model']['hidden_layers'] = [256, 128, 64]  # æ›´å¤§çš„ç½‘ç»œå¤„ç†é«˜ç»´æ•°æ®
    
    success = train_with_custom_data(X, y, config, "ä¼ æ„Ÿå™¨æ•°æ®é¢„æµ‹æ¨¡å‹")
    
    return X, y, success


def example_5_image_features():
    """
    ç¤ºä¾‹5: å›¾åƒç‰¹å¾æ•°æ®
    é€‚ç”¨åœºæ™¯: ä»å›¾åƒæå–çš„ç‰¹å¾è¿›è¡Œå›å½’é¢„æµ‹
    """
    print("\n" + "="*60)
    print("ç¤ºä¾‹5: å›¾åƒç‰¹å¾æ•°æ®")
    print("="*60)
    
    # æ¨¡æ‹Ÿä»å›¾åƒæå–çš„ç‰¹å¾ (å¦‚CNNç‰¹å¾)
    np.random.seed(42)
    n_samples = 500
    
    # å‡è®¾ä»é¢„è®­ç»ƒCNNæ¨¡å‹æå–çš„ç‰¹å¾å‘é‡
    feature_dim = 512  # å¸¸è§çš„ç‰¹å¾ç»´åº¦
    
    # ç”Ÿæˆå›¾åƒç‰¹å¾ (æ¨¡æ‹ŸResNetç­‰æå–çš„ç‰¹å¾)
    X = np.random.normal(0, 1, (n_samples, feature_dim)).astype(np.float32)
    
    # æ·»åŠ ä¸€äº›ç»“æ„åŒ–ä¿¡æ¯
    # å‡è®¾å‰100ç»´æ˜¯é¢œè‰²ç‰¹å¾ï¼Œä¸­é—´200ç»´æ˜¯çº¹ç†ç‰¹å¾ï¼Œåé¢æ˜¯å½¢çŠ¶ç‰¹å¾
    X[:, :100] = np.abs(X[:, :100])  # é¢œè‰²ç‰¹å¾é€šå¸¸ä¸ºæ­£
    X[:, 100:300] = X[:, 100:300] * 2  # çº¹ç†ç‰¹å¾æ–¹å·®æ›´å¤§
    
    # ç”Ÿæˆç›®æ ‡å˜é‡ (å›¾åƒè´¨é‡è¯„åˆ†)
    # ç›®æ ‡1: ç¾å­¦è¯„åˆ† (1-10), ç›®æ ‡2: æŠ€æœ¯è´¨é‡è¯„åˆ† (1-10), ç›®æ ‡3: æƒ…æ„Ÿè¯„åˆ† (-5åˆ°5)
    
    # ç¾å­¦è¯„åˆ†ä¸»è¦ä¾èµ–é¢œè‰²å’Œæ„å›¾ç‰¹å¾
    aesthetic_score = (
        np.mean(X[:, :50], axis=1) * 2 +  # é¢œè‰²ç‰¹å¾
        np.mean(X[:, 400:450], axis=1) * 1.5 +  # æ„å›¾ç‰¹å¾
        np.random.normal(0, 0.5, n_samples)
    )
    aesthetic_score = np.clip(aesthetic_score + 5, 1, 10)  # ç¼©æ”¾åˆ°1-10
    
    # æŠ€æœ¯è´¨é‡ä¸»è¦ä¾èµ–çº¹ç†å’Œæ¸…æ™°åº¦ç‰¹å¾
    technical_score = (
        np.mean(X[:, 100:200], axis=1) * 1.5 +  # çº¹ç†ç‰¹å¾
        np.mean(X[:, 300:350], axis=1) * 2 +    # æ¸…æ™°åº¦ç‰¹å¾
        np.random.normal(0, 0.3, n_samples)
    )
    technical_score = np.clip(technical_score + 5, 1, 10)
    
    # æƒ…æ„Ÿè¯„åˆ†ä¾èµ–å¤šç§ç‰¹å¾çš„å¤æ‚ç»„åˆ
    emotion_score = (
        np.mean(X[:, 50:100], axis=1) * 1.2 +   # è‰²å½©æƒ…æ„Ÿ
        np.mean(X[:, 450:500], axis=1) * 0.8 +  # å†…å®¹æƒ…æ„Ÿ
        np.random.normal(0, 0.4, n_samples)
    )
    emotion_score = np.clip(emotion_score, -5, 5)
    
    y = np.column_stack([aesthetic_score, technical_score, emotion_score]).astype(np.float32)
    
    print(f"æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}")
    print(f"è¾“å…¥ç‰¹å¾: {feature_dim}ç»´å›¾åƒç‰¹å¾å‘é‡")
    print(f"è¾“å‡ºç›®æ ‡: ç¾å­¦è¯„åˆ†(1-10), æŠ€æœ¯è´¨é‡(1-10), æƒ…æ„Ÿè¯„åˆ†(-5åˆ°5)")
    print(f"ç‰¹å¾ç»Ÿè®¡:")
    print(f"  ç‰¹å¾å‡å€¼: {X.mean():.3f}, æ ‡å‡†å·®: {X.std():.3f}")
    print(f"  ç›®æ ‡å‡å€¼: {y.mean(axis=0)}")
    print(f"  ç›®æ ‡æ ‡å‡†å·®: {y.std(axis=0)}")
    
    # ä½¿ç”¨æ•°æ®è®­ç»ƒæ¨¡å‹
    config = load_config()
    config['training']['epochs'] = 20
    config['model']['hidden_layers'] = [256, 128, 64, 32]  # æ·±å±‚ç½‘ç»œå¤„ç†é«˜ç»´ç‰¹å¾
    config['model']['dropout_rate'] = 0.3  # é«˜ç»´æ•°æ®éœ€è¦æ›´å¤šæ­£åˆ™åŒ–
    
    success = train_with_custom_data(X, y, config, "å›¾åƒè´¨é‡è¯„ä¼°æ¨¡å‹")
    
    return X, y, success


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open('config.yaml', 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def train_with_custom_data(X: np.ndarray, y: np.ndarray, config: dict, model_name: str) -> bool:
    """ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®è®­ç»ƒæ¨¡å‹"""
    try:
        print(f"\nå¼€å§‹è®­ç»ƒ {model_name}...")
        
        # åˆ›å»ºæ•°æ®å¤„ç†å™¨
        processor = DataProcessor(config)
        processor.load_data_from_arrays(X, y)
        processor.normalize_data()
        
        # åˆ†å‰²æ•°æ®
        X_train, X_val, X_test, y_train, y_val, y_test = processor.split_data()
        train_loader, val_loader, test_loader = processor.create_data_loaders(
            X_train, X_val, X_test, y_train, y_val, y_test
        )
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model_from_config(config, processor.input_dim, processor.output_dim)
        print(f"æ¨¡å‹ä¿¡æ¯: {model.get_model_info()}")
        
        # è®­ç»ƒæ¨¡å‹
        trainer = MLPTrainer(model, config)
        history = trainer.train(train_loader, val_loader)
        
        # è¯„ä¼°æ¨¡å‹
        evaluator = ModelEvaluator(save_plots=False)  # ä¸ä¿å­˜å›¾ç‰‡ï¼Œé¿å…æ–‡ä»¶è¿‡å¤š
        
        test_pred, test_true = trainer.predict(test_loader)
        test_pred_orig = processor.inverse_transform_predictions(test_pred)
        test_true_orig = processor.inverse_transform_predictions(test_true)
        
        metrics = evaluator.evaluate_model(test_true_orig, test_pred_orig, "test")
        
        print(f"âœ… {model_name} è®­ç»ƒæˆåŠŸ!")
        print(f"   æœ€ç»ˆRÂ²åˆ†æ•°: {metrics['r2']:.4f}")
        print(f"   RMSE: {metrics['rmse']:.4f}")
        print(f"   MAE: {metrics['mae']:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ {model_name} è®­ç»ƒå¤±è´¥: {e}")
        return False


def train_with_processor(processor: DataProcessor, config: dict, model_name: str) -> bool:
    """ä½¿ç”¨å·²é…ç½®çš„å¤„ç†å™¨è®­ç»ƒæ¨¡å‹"""
    try:
        print(f"\nå¼€å§‹è®­ç»ƒ {model_name}...")
        
        processor.normalize_data()
        
        # åˆ†å‰²æ•°æ®
        X_train, X_val, X_test, y_train, y_val, y_test = processor.split_data()
        train_loader, val_loader, test_loader = processor.create_data_loaders(
            X_train, X_val, X_test, y_train, y_val, y_test
        )
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model_from_config(config, processor.input_dim, processor.output_dim)
        
        # è®­ç»ƒæ¨¡å‹
        trainer = MLPTrainer(model, config)
        history = trainer.train(train_loader, val_loader)
        
        # è¯„ä¼°æ¨¡å‹
        evaluator = ModelEvaluator(save_plots=False)
        
        test_pred, test_true = trainer.predict(test_loader)
        test_pred_orig = processor.inverse_transform_predictions(test_pred)
        test_true_orig = processor.inverse_transform_predictions(test_true)
        
        metrics = evaluator.evaluate_model(test_true_orig, test_pred_orig, "test")
        
        print(f"âœ… {model_name} è®­ç»ƒæˆåŠŸ!")
        print(f"   æœ€ç»ˆRÂ²åˆ†æ•°: {metrics['r2']:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ {model_name} è®­ç»ƒå¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰è‡ªå®šä¹‰æ•°æ®ç¤ºä¾‹"""
    print("ğŸš€ MLPè‡ªå®šä¹‰æ•°æ®é›†ç¤ºä¾‹æ¼”ç¤º")
    print("æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•å°†ä¸åŒæ ¼å¼çš„æ•°æ®è½¬æ¢ä¸ºé¡¹ç›®å¯ç”¨çš„æ ¼å¼")
    
    results = []
    
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    examples = [
        ("NumPyæ•°ç»„", example_1_numpy_arrays),
        ("Pandas DataFrame", example_2_pandas_dataframe), 
        ("CSVæ–‡ä»¶", example_3_csv_file),
        ("æ—¶é—´åºåˆ—", example_4_time_series_data),
        ("å›¾åƒç‰¹å¾", example_5_image_features)
    ]
    
    for name, example_func in examples:
        try:
            print(f"\n{'='*20} è¿è¡Œ{name}ç¤ºä¾‹ {'='*20}")
            X, y, success = example_func()
            results.append((name, success, X.shape, y.shape))
        except Exception as e:
            print(f"âŒ {name}ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
            results.append((name, False, None, None))
    
    # æ€»ç»“ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š ç¤ºä¾‹è¿è¡Œæ€»ç»“")
    print("="*60)
    
    for name, success, x_shape, y_shape in results:
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        shapes = f"X{x_shape}, y{y_shape}" if x_shape else "N/A"
        print(f"{name:15} | {status:6} | æ•°æ®å½¢çŠ¶: {shapes}")
    
    successful_count = sum(1 for _, success, _, _ in results if success)
    print(f"\næˆåŠŸè¿è¡Œ: {successful_count}/{len(results)} ä¸ªç¤ºä¾‹")
    
    if successful_count > 0:
        print("\nğŸ‰ æ­å–œï¼æ‚¨å·²ç»å­¦ä¼šäº†å¦‚ä½•åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†ï¼")
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("1. æ ¹æ®æ‚¨çš„æ•°æ®ç±»å‹é€‰æ‹©åˆé€‚çš„ç¤ºä¾‹ä½œä¸ºæ¨¡æ¿")
        print("2. ç¡®ä¿è¾“å…¥æ•°æ®Xä¸ºfloat32ç±»å‹çš„2Dæ•°ç»„ (n_samples, n_features)")
        print("3. ç¡®ä¿è¾“å‡ºæ•°æ®yä¸ºfloat32ç±»å‹çš„2Dæ•°ç»„ (n_samples, n_targets)")
        print("4. æ ¹æ®æ•°æ®ç‰¹æ€§è°ƒæ•´ç½‘ç»œç»“æ„å’Œè¶…å‚æ•°")
        print("5. ä½¿ç”¨æ•°æ®æ ‡å‡†åŒ–æå‡è®­ç»ƒæ•ˆæœ")


if __name__ == "__main__":
    main()