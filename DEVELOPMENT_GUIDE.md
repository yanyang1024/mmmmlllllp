# MLPæ•°å€¼é¢„æµ‹æ¨¡å‹å¼€å‘æŒ‡å—

æœ¬æ–‡æ¡£ä¸ºå¼€å‘è€…æä¾›äº†é¡¹ç›®æ¶æ„è¯´æ˜ã€æ‰©å±•å¼€å‘æŒ‡å¯¼å’Œä»£ç è§„èŒƒï¼Œå¸®åŠ©è¿›è¡Œé«˜æ•ˆçš„äºŒæ¬¡å¼€å‘ã€‚

## ğŸ—ï¸ é¡¹ç›®æ¶æ„åˆ†æ

### 1. æ ¸å¿ƒæ¨¡å—æ¶æ„

```
mlp/
â”œâ”€â”€ ğŸ“Š æ•°æ®å±‚ (Data Layer)
â”‚   â”œâ”€â”€ data_processor.py      # æ•°æ®å¤„ç†æ ¸å¿ƒ
â”‚   â”œâ”€â”€ NumericalDataset       # PyTorchæ•°æ®é›†
â”‚   â””â”€â”€ DataProcessor          # æ•°æ®é¢„å¤„ç†ç®¡é“
â”‚
â”œâ”€â”€ ğŸ§  æ¨¡å‹å±‚ (Model Layer)
â”‚   â”œâ”€â”€ mlp_model.py           # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ MLPModel               # æ ¸å¿ƒMLPæ¶æ„
â”‚   â”œâ”€â”€ EarlyStopping          # æ—©åœæœºåˆ¶
â”‚   â””â”€â”€ ModelCheckpoint        # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚
â”œâ”€â”€ ğŸ¯ è®­ç»ƒå±‚ (Training Layer)
â”‚   â”œâ”€â”€ trainer.py             # è®­ç»ƒç®¡ç†
â”‚   â””â”€â”€ MLPTrainer             # è®­ç»ƒå™¨æ ¸å¿ƒ
â”‚
â”œâ”€â”€ ğŸ“ˆ è¯„ä¼°å±‚ (Evaluation Layer)
â”‚   â”œâ”€â”€ evaluator.py           # æ¨¡å‹è¯„ä¼°
â”‚   â””â”€â”€ ModelEvaluator         # è¯„ä¼°å™¨æ ¸å¿ƒ
â”‚
â””â”€â”€ ğŸ”§ åº”ç”¨å±‚ (Application Layer)
    â”œâ”€â”€ main.py                # ä¸»ç¨‹åºå…¥å£
    â”œâ”€â”€ example_usage.py       # ä½¿ç”¨ç¤ºä¾‹
    â””â”€â”€ config.yaml            # é…ç½®ç®¡ç†
```

### 2. æ•°æ®æµæ¶æ„

```mermaid
graph TD
    A[åŸå§‹æ•°æ®] --> B[DataProcessor]
    B --> C[æ•°æ®æ ‡å‡†åŒ–]
    C --> D[æ•°æ®åˆ†å‰²]
    D --> E[DataLoader]
    E --> F[MLPModel]
    F --> G[MLPTrainer]
    G --> H[è®­ç»ƒå¾ªç¯]
    H --> I[ModelEvaluator]
    I --> J[ç»“æœè¾“å‡º]
```

### 3. ç±»å…³ç³»å›¾

```python
# æ ¸å¿ƒç±»ç»§æ‰¿å’Œä¾èµ–å…³ç³»
class NumericalDataset(Dataset):
    """PyTorchæ•°æ®é›†åŸºç±»"""
    pass

class DataProcessor:
    """æ•°æ®å¤„ç†ç®¡é“"""
    def __init__(self, config: dict)
    def load_data_from_arrays(self, X, y)
    def normalize_data(self)
    def split_data(self)

class MLPModel(nn.Module):
    """MLPæ¨¡å‹æ ¸å¿ƒ"""
    def __init__(self, input_dim, output_dim, hidden_layers, ...)
    def forward(self, x)
    def predict(self, x)

class MLPTrainer:
    """è®­ç»ƒç®¡ç†å™¨"""
    def __init__(self, model, config, device)
    def train(self, train_loader, val_loader)
    def predict(self, data_loader)

class ModelEvaluator:
    """è¯„ä¼°ç®¡ç†å™¨"""
    def evaluate_model(self, y_true, y_pred)
    def plot_predictions_vs_actual(self, ...)
```

## ğŸ”§ æ‰©å±•å¼€å‘æŒ‡å—

### 1. æ·»åŠ æ–°çš„æ¨¡å‹æ¶æ„

#### æ­¥éª¤1ï¼šåˆ›å»ºæ–°æ¨¡å‹ç±»
```python
# åœ¨mlp_model.pyä¸­æ·»åŠ 
class CustomMLPModel(MLPModel):
    """è‡ªå®šä¹‰MLPæ¨¡å‹"""
    
    def __init__(self, input_dim, output_dim, custom_param=None, **kwargs):
        super().__init__(input_dim, output_dim, **kwargs)
        self.custom_param = custom_param
        
        # æ·»åŠ è‡ªå®šä¹‰å±‚
        self.custom_layer = nn.Linear(self.hidden_layers[-1], self.hidden_layers[-1])
    
    def forward(self, x):
        # è°ƒç”¨çˆ¶ç±»çš„å‰å‘ä¼ æ’­åˆ°æœ€åä¸€ä¸ªéšè—å±‚
        x = self._forward_to_last_hidden(x)
        
        # æ·»åŠ è‡ªå®šä¹‰å¤„ç†
        x = self.custom_layer(x)
        x = torch.relu(x)
        
        # è¾“å‡ºå±‚
        return self.output_layer(x)
    
    def _forward_to_last_hidden(self, x):
        """å‰å‘ä¼ æ’­åˆ°æœ€åä¸€ä¸ªéšè—å±‚"""
        for i, layer in enumerate(self.layers):
            x = layer(x)
            if self.batch_norm and self.batch_norms is not None:
                x = self.batch_norms[i](x)
            x = self._get_activation(x)
            x = self.dropouts[i](x)
        return x
```

#### æ­¥éª¤2ï¼šæ›´æ–°é…ç½®æ”¯æŒ
```yaml
# åœ¨config.yamlä¸­æ·»åŠ 
model:
  type: "custom_mlp"  # æ–°å¢æ¨¡å‹ç±»å‹
  custom_param: 0.5   # è‡ªå®šä¹‰å‚æ•°
```

#### æ­¥éª¤3ï¼šæ›´æ–°æ¨¡å‹åˆ›å»ºå‡½æ•°
```python
# åœ¨mlp_model.pyä¸­ä¿®æ”¹
def create_model_from_config(config: dict, input_dim: int, output_dim: int) -> MLPModel:
    model_config = config['model']
    model_type = model_config.get('type', 'standard')
    
    if model_type == 'custom_mlp':
        return CustomMLPModel(
            input_dim=input_dim,
            output_dim=output_dim,
            hidden_layers=model_config['hidden_layers'],
            activation=model_config['activation'],
            dropout_rate=model_config['dropout_rate'],
            custom_param=model_config.get('custom_param', 0.5)
        )
    else:
        return MLPModel(
            input_dim=input_dim,
            output_dim=output_dim,
            hidden_layers=model_config['hidden_layers'],
            activation=model_config['activation'],
            dropout_rate=model_config['dropout_rate']
        )
```

### 2. æ·»åŠ æ–°çš„æ•°æ®å¤„ç†åŠŸèƒ½

#### åˆ›å»ºæ•°æ®å¤„ç†æ’ä»¶
```python
# åˆ›å»ºdata_plugins.py
class DataProcessingPlugin:
    """æ•°æ®å¤„ç†æ’ä»¶åŸºç±»"""
    
    def __init__(self, config):
        self.config = config
    
    def process(self, X, y):
        """å¤„ç†æ•°æ®çš„æŠ½è±¡æ–¹æ³•"""
        raise NotImplementedError

class OutlierRemovalPlugin(DataProcessingPlugin):
    """å¼‚å¸¸å€¼ç§»é™¤æ’ä»¶"""
    
    def process(self, X, y):
        from sklearn.ensemble import IsolationForest
        
        # ä½¿ç”¨å­¤ç«‹æ£®æ—æ£€æµ‹å¼‚å¸¸å€¼
        iso_forest = IsolationForest(
            contamination=self.config.get('contamination', 0.1),
            random_state=42
        )
        
        outlier_mask = iso_forest.fit_predict(X) == 1
        
        logger.info(f"ç§»é™¤äº† {(~outlier_mask).sum()} ä¸ªå¼‚å¸¸å€¼")
        
        return X[outlier_mask], y[outlier_mask]

class FeatureEngineeringPlugin(DataProcessingPlugin):
    """ç‰¹å¾å·¥ç¨‹æ’ä»¶"""
    
    def process(self, X, y):
        from sklearn.preprocessing import PolynomialFeatures
        
        if self.config.get('polynomial_features', False):
            poly = PolynomialFeatures(
                degree=self.config.get('poly_degree', 2),
                include_bias=False
            )
            X_poly = poly.fit_transform(X)
            logger.info(f"å¤šé¡¹å¼ç‰¹å¾å·¥ç¨‹ï¼š{X.shape[1]} -> {X_poly.shape[1]} ç‰¹å¾")
            return X_poly, y
        
        return X, y
```

#### é›†æˆåˆ°DataProcessor
```python
# åœ¨data_processor.pyä¸­æ·»åŠ 
class DataProcessor:
    def __init__(self, config: dict):
        self.config = config
        self.plugins = self._load_plugins()
    
    def _load_plugins(self):
        """åŠ è½½æ•°æ®å¤„ç†æ’ä»¶"""
        plugins = []
        plugin_config = self.config.get('data_plugins', {})
        
        if plugin_config.get('outlier_removal', False):
            plugins.append(OutlierRemovalPlugin(plugin_config))
        
        if plugin_config.get('feature_engineering', False):
            plugins.append(FeatureEngineeringPlugin(plugin_config))
        
        return plugins
    
    def apply_plugins(self, X, y):
        """åº”ç”¨æ‰€æœ‰æ’ä»¶"""
        for plugin in self.plugins:
            X, y = plugin.process(X, y)
        return X, y
    
    def load_data_from_arrays(self, X: np.ndarray, y: np.ndarray) -> None:
        # åŸæœ‰é€»è¾‘...
        
        # åº”ç”¨æ’ä»¶
        X, y = self.apply_plugins(X, y)
        
        # ç»§ç»­åŸæœ‰é€»è¾‘...
```

### 3. æ·»åŠ æ–°çš„è®­ç»ƒç­–ç•¥

#### åˆ›å»ºè®­ç»ƒç­–ç•¥æ’ä»¶
```python
# åˆ›å»ºtraining_strategies.py
class TrainingStrategy:
    """è®­ç»ƒç­–ç•¥åŸºç±»"""
    
    def __init__(self, trainer):
        self.trainer = trainer
    
    def train_epoch(self, train_loader):
        """è®­ç»ƒä¸€ä¸ªepochçš„æŠ½è±¡æ–¹æ³•"""
        raise NotImplementedError

class AdversarialTrainingStrategy(TrainingStrategy):
    """å¯¹æŠ—è®­ç»ƒç­–ç•¥"""
    
    def __init__(self, trainer, epsilon=0.01):
        super().__init__(trainer)
        self.epsilon = epsilon
    
    def train_epoch(self, train_loader):
        """å¯¹æŠ—è®­ç»ƒepoch"""
        self.trainer.model.train()
        total_loss = 0.0
        
        for data, target in train_loader:
            data, target = data.to(self.trainer.device), target.to(self.trainer.device)
            
            # ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
            data_adv = self._generate_adversarial_examples(data, target)
            
            # æ­£å¸¸æ ·æœ¬è®­ç»ƒ
            self.trainer.optimizer.zero_grad()
            output = self.trainer.model(data)
            loss_clean = self.trainer.criterion(output, target)
            
            # å¯¹æŠ—æ ·æœ¬è®­ç»ƒ
            output_adv = self.trainer.model(data_adv)
            loss_adv = self.trainer.criterion(output_adv, target)
            
            # æ€»æŸå¤±
            loss = 0.5 * (loss_clean + loss_adv)
            loss.backward()
            self.trainer.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / len(train_loader)
    
    def _generate_adversarial_examples(self, data, target):
        """ç”Ÿæˆå¯¹æŠ—æ ·æœ¬"""
        data.requires_grad_(True)
        
        output = self.trainer.model(data)
        loss = self.trainer.criterion(output, target)
        
        grad = torch.autograd.grad(loss, data, create_graph=False)[0]
        data_adv = data + self.epsilon * grad.sign()
        
        return data_adv.detach()

class MixupTrainingStrategy(TrainingStrategy):
    """Mixupè®­ç»ƒç­–ç•¥"""
    
    def __init__(self, trainer, alpha=0.2):
        super().__init__(trainer)
        self.alpha = alpha
    
    def train_epoch(self, train_loader):
        """Mixupè®­ç»ƒepoch"""
        self.trainer.model.train()
        total_loss = 0.0
        
        for data, target in train_loader:
            data, target = data.to(self.trainer.device), target.to(self.trainer.device)
            
            # Mixup
            mixed_data, mixed_target = self._mixup_data(data, target)
            
            self.trainer.optimizer.zero_grad()
            output = self.trainer.model(mixed_data)
            loss = self.trainer.criterion(output, mixed_target)
            loss.backward()
            self.trainer.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / len(train_loader)
    
    def _mixup_data(self, x, y):
        """æ‰§è¡ŒMixup"""
        if self.alpha > 0:
            lam = np.random.beta(self.alpha, self.alpha)
        else:
            lam = 1
        
        batch_size = x.size(0)
        index = torch.randperm(batch_size).to(x.device)
        
        mixed_x = lam * x + (1 - lam) * x[index]
        mixed_y = lam * y + (1 - lam) * y[index]
        
        return mixed_x, mixed_y
```

### 4. æ·»åŠ æ–°çš„è¯„ä¼°æŒ‡æ ‡

#### åˆ›å»ºè‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡
```python
# åœ¨evaluator.pyä¸­æ·»åŠ 
class CustomMetrics:
    """è‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡é›†åˆ"""
    
    @staticmethod
    def concordance_correlation_coefficient(y_true, y_pred):
        """ä¸€è‡´æ€§ç›¸å…³ç³»æ•°"""
        mean_true = np.mean(y_true)
        mean_pred = np.mean(y_pred)
        
        var_true = np.var(y_true)
        var_pred = np.var(y_pred)
        
        covariance = np.mean((y_true - mean_true) * (y_pred - mean_pred))
        
        ccc = (2 * covariance) / (var_true + var_pred + (mean_true - mean_pred)**2)
        return ccc
    
    @staticmethod
    def mean_absolute_percentage_error_symmetric(y_true, y_pred):
        """å¯¹ç§°å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®"""
        return np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + 1e-8)) * 100
    
    @staticmethod
    def normalized_root_mean_squared_error(y_true, y_pred):
        """æ ‡å‡†åŒ–å‡æ–¹æ ¹è¯¯å·®"""
        rmse = np.sqrt(np.mean((y_true - y_pred)**2))
        return rmse / (np.max(y_true) - np.min(y_true))

# æ›´æ–°calculate_metricså‡½æ•°
def calculate_metrics_extended(y_true: np.ndarray, y_pred: np.ndarray) -> dict:
    """æ‰©å±•çš„è¯„ä¼°æŒ‡æ ‡è®¡ç®—"""
    basic_metrics = calculate_metrics(y_true, y_pred)
    
    # æ·»åŠ è‡ªå®šä¹‰æŒ‡æ ‡
    custom_metrics = {
        'ccc': CustomMetrics.concordance_correlation_coefficient(y_true, y_pred),
        'smape_custom': CustomMetrics.mean_absolute_percentage_error_symmetric(y_true, y_pred),
        'nrmse': CustomMetrics.normalized_root_mean_squared_error(y_true, y_pred)
    }
    
    return {**basic_metrics, **custom_metrics}
```

## ğŸ¯ å¼€å‘è§„èŒƒå’Œæœ€ä½³å®è·µ

### 1. ä»£ç é£æ ¼è§„èŒƒ

#### Pythonä»£ç è§„èŒƒ
```python
# éµå¾ªPEP 8è§„èŒƒ
# ä½¿ç”¨ç±»å‹æ³¨è§£
def process_data(X: np.ndarray, y: np.ndarray, config: Dict[str, Any]) -> Tuple[np.ndarray, np.ndarray]:
    """
    å¤„ç†æ•°æ®çš„å‡½æ•°
    
    Args:
        X: è¾“å…¥ç‰¹å¾æ•°ç»„
        y: ç›®æ ‡å€¼æ•°ç»„
        config: é…ç½®å­—å…¸
        
    Returns:
        å¤„ç†åçš„Xå’Œy
        
    Raises:
        ValueError: å½“è¾“å…¥æ•°æ®æ ¼å¼ä¸æ­£ç¡®æ—¶
    """
    if X.ndim != 2:
        raise ValueError(f"Xåº”è¯¥æ˜¯2ç»´æ•°ç»„ï¼Œä½†å¾—åˆ°äº†{X.ndim}ç»´")
    
    # å¤„ç†é€»è¾‘...
    return X_processed, y_processed

# ä½¿ç”¨dataclasså®šä¹‰é…ç½®
from dataclasses import dataclass
from typing import List, Optional

@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®ç±»"""
    input_dim: int
    output_dim: int
    hidden_layers: List[int]
    activation: str = "relu"
    dropout_rate: float = 0.2
    batch_norm: bool = False
```

#### æ—¥å¿—è§„èŒƒ
```python
# ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼
from loguru import logger

# ä¿¡æ¯æ—¥å¿—
logger.info("å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œå‚æ•°: {}", model_params)

# è­¦å‘Šæ—¥å¿—
logger.warning("æ£€æµ‹åˆ°å¼‚å¸¸å€¼ {} ä¸ªï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡", outlier_count)

# é”™è¯¯æ—¥å¿—
logger.error("æ¨¡å‹è®­ç»ƒå¤±è´¥: {}", str(e))

# è°ƒè¯•æ—¥å¿—
logger.debug("ä¸­é—´ç»“æœ: shape={}, mean={:.4f}", data.shape, data.mean())
```

### 2. æµ‹è¯•è§„èŒƒ

#### å•å…ƒæµ‹è¯•ç¤ºä¾‹
```python
# åˆ›å»ºtests/test_data_processor.py
import unittest
import numpy as np
from data_processor import DataProcessor, generate_sample_data

class TestDataProcessor(unittest.TestCase):
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.config = {
            'data': {
                'train_ratio': 0.8,
                'val_ratio': 0.1,
                'test_ratio': 0.1,
                'random_seed': 42,
                'normalize': True
            }
        }
        self.processor = DataProcessor(self.config)
    
    def test_load_data_from_arrays(self):
        """æµ‹è¯•ä»æ•°ç»„åŠ è½½æ•°æ®"""
        X = np.random.randn(100, 5)
        y = np.random.randn(100, 2)
        
        self.processor.load_data_from_arrays(X, y)
        
        self.assertEqual(self.processor.input_dim, 5)
        self.assertEqual(self.processor.output_dim, 2)
        np.testing.assert_array_equal(self.processor.X_raw, X)
        np.testing.assert_array_equal(self.processor.y_raw, y)
    
    def test_normalize_data(self):
        """æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–"""
        X = np.random.randn(100, 5) * 10 + 5
        y = np.random.randn(100, 2) * 20 + 10
        
        self.processor.load_data_from_arrays(X, y)
        self.processor.normalize_data()
        
        # æ£€æŸ¥æ ‡å‡†åŒ–åçš„æ•°æ®å‡å€¼æ¥è¿‘0ï¼Œæ ‡å‡†å·®æ¥è¿‘1
        self.assertAlmostEqual(self.processor.X_processed.mean(), 0, places=1)
        self.assertAlmostEqual(self.processor.X_processed.std(), 1, places=1)
    
    def test_split_data(self):
        """æµ‹è¯•æ•°æ®åˆ†å‰²"""
        X = np.random.randn(100, 5)
        y = np.random.randn(100, 2)
        
        self.processor.load_data_from_arrays(X, y)
        self.processor.normalize_data()
        
        X_train, X_val, X_test, y_train, y_val, y_test = self.processor.split_data()
        
        # æ£€æŸ¥åˆ†å‰²æ¯”ä¾‹
        total_samples = len(X)
        self.assertEqual(len(X_train), int(total_samples * 0.8))
        self.assertEqual(len(X_val), int(total_samples * 0.1))
        self.assertEqual(len(X_test), int(total_samples * 0.1))

if __name__ == '__main__':
    unittest.main()
```

#### é›†æˆæµ‹è¯•ç¤ºä¾‹
```python
# åˆ›å»ºtests/test_integration.py
import unittest
import tempfile
import os
from main import prepare_data, train_model, evaluate_model, load_config

class TestIntegration(unittest.TestCase):
    
    def setUp(self):
        """åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶"""
        self.temp_dir = tempfile.mkdtemp()
        self.config = load_config('config.yaml')
        # å‡å°‘è®­ç»ƒæ—¶é—´ç”¨äºæµ‹è¯•
        self.config['training']['epochs'] = 5
        self.config['model']['hidden_layers'] = [32, 16]
    
    def test_full_pipeline(self):
        """æµ‹è¯•å®Œæ•´çš„è®­ç»ƒå’Œè¯„ä¼°æµç¨‹"""
        # å‡†å¤‡æ•°æ®
        processor, data_loaders = prepare_data(self.config, data_source="sample")
        
        # è®­ç»ƒæ¨¡å‹
        trainer = train_model(self.config, processor, data_loaders, self.temp_dir)
        
        # è¯„ä¼°æ¨¡å‹
        results = evaluate_model(trainer, processor, data_loaders, save_plots=False)
        
        # æ£€æŸ¥ç»“æœ
        self.assertIn('test_metrics', results)
        self.assertIn('r2', results['test_metrics'])
        self.assertIsInstance(results['test_metrics']['r2'], float)
    
    def tearDown(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        import shutil
        shutil.rmtree(self.temp_dir)
```

### 3. æ€§èƒ½ç›‘æ§

#### åˆ›å»ºæ€§èƒ½ç›‘æ§å·¥å…·
```python
# åˆ›å»ºperformance_monitor.py
import time
import psutil
import torch
from functools import wraps
from typing import Dict, Any

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics = {}
    
    def monitor_function(self, func_name: str = None):
        """å‡½æ•°æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                name = func_name or func.__name__
                
                # è®°å½•å¼€å§‹çŠ¶æ€
                start_time = time.time()
                start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
                
                if torch.cuda.is_available():
                    start_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024  # MB
                
                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)
                
                # è®°å½•ç»“æŸçŠ¶æ€
                end_time = time.time()
                end_memory = psutil.Process().memory_info().rss / 1024 / 1024
                
                # è®¡ç®—æŒ‡æ ‡
                execution_time = end_time - start_time
                memory_usage = end_memory - start_memory
                
                metrics = {
                    'execution_time': execution_time,
                    'memory_usage': memory_usage,
                    'timestamp': time.time()
                }
                
                if torch.cuda.is_available():
                    end_gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024
                    metrics['gpu_memory_usage'] = end_gpu_memory - start_gpu_memory
                
                self.metrics[name] = metrics
                
                logger.info(f"{name} æ‰§è¡Œå®Œæˆ: æ—¶é—´={execution_time:.2f}s, å†…å­˜={memory_usage:.2f}MB")
                
                return result
            return wrapper
        return decorator
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        if not self.metrics:
            return {}
        
        total_time = sum(m['execution_time'] for m in self.metrics.values())
        total_memory = sum(m['memory_usage'] for m in self.metrics.values())
        
        return {
            'total_execution_time': total_time,
            'total_memory_usage': total_memory,
            'function_count': len(self.metrics),
            'detailed_metrics': self.metrics
        }

# ä½¿ç”¨ç¤ºä¾‹
monitor = PerformanceMonitor()

class MLPTrainer:
    @monitor.monitor_function("train_epoch")
    def train_epoch(self, train_loader):
        # åŸæœ‰è®­ç»ƒé€»è¾‘...
        pass
```

### 4. é…ç½®ç®¡ç†æœ€ä½³å®è·µ

#### åˆ†å±‚é…ç½®ç³»ç»Ÿ
```python
# åˆ›å»ºconfig_manager.py
import yaml
import os
from typing import Dict, Any, Optional
from pathlib import Path

class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, base_config_path: str = "config.yaml"):
        self.base_config_path = base_config_path
        self.config = self._load_base_config()
    
    def _load_base_config(self) -> Dict[str, Any]:
        """åŠ è½½åŸºç¡€é…ç½®"""
        with open(self.base_config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def load_experiment_config(self, experiment_name: str) -> Dict[str, Any]:
        """åŠ è½½å®éªŒé…ç½®"""
        experiment_path = f"experiments/{experiment_name}.yaml"
        
        if os.path.exists(experiment_path):
            with open(experiment_path, 'r', encoding='utf-8') as f:
                experiment_config = yaml.safe_load(f)
            
            # åˆå¹¶é…ç½®
            merged_config = self._deep_merge(self.config.copy(), experiment_config)
            return merged_config
        else:
            logger.warning(f"å®éªŒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {experiment_path}")
            return self.config.copy()
    
    def _deep_merge(self, base: Dict, override: Dict) -> Dict:
        """æ·±åº¦åˆå¹¶å­—å…¸"""
        for key, value in override.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                base[key] = self._deep_merge(base[key], value)
            else:
                base[key] = value
        return base
    
    def save_config(self, config: Dict[str, Any], save_path: str):
        """ä¿å­˜é…ç½®"""
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    def validate_config(self, config: Dict[str, Any]) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        required_keys = [
            'data.train_ratio',
            'data.val_ratio', 
            'data.test_ratio',
            'model.hidden_layers',
            'training.batch_size',
            'training.epochs'
        ]
        
        for key_path in required_keys:
            if not self._check_nested_key(config, key_path):
                logger.error(f"é…ç½®ç¼ºå°‘å¿…éœ€çš„é”®: {key_path}")
                return False
        
        # éªŒè¯æ•°æ®åˆ†å‰²æ¯”ä¾‹
        ratios = [config['data']['train_ratio'], 
                 config['data']['val_ratio'], 
                 config['data']['test_ratio']]
        if abs(sum(ratios) - 1.0) > 1e-6:
            logger.error("æ•°æ®åˆ†å‰²æ¯”ä¾‹ä¹‹å’Œå¿…é¡»ç­‰äº1.0")
            return False
        
        return True
    
    def _check_nested_key(self, config: Dict, key_path: str) -> bool:
        """æ£€æŸ¥åµŒå¥—é”®æ˜¯å¦å­˜åœ¨"""
        keys = key_path.split('.')
        current = config
        
        for key in keys:
            if not isinstance(current, dict) or key not in current:
                return False
            current = current[key]
        
        return True

# å®éªŒé…ç½®ç¤ºä¾‹
# experiments/high_capacity.yaml
"""
model:
  hidden_layers: [512, 256, 128, 64]
  dropout_rate: 0.3

training:
  batch_size: 64
  epochs: 200
  learning_rate: 0.0001
"""

# experiments/fast_training.yaml
"""
model:
  hidden_layers: [64, 32]
  dropout_rate: 0.1

training:
  batch_size: 128
  epochs: 50
  learning_rate: 0.01
"""
```

## ğŸ“š APIæ–‡æ¡£ç”Ÿæˆ

### è‡ªåŠ¨æ–‡æ¡£ç”Ÿæˆ
```python
# åˆ›å»ºdocs/generate_docs.py
import inspect
import importlib
from pathlib import Path

def generate_api_docs():
    """ç”ŸæˆAPIæ–‡æ¡£"""
    modules = ['data_processor', 'mlp_model', 'trainer', 'evaluator']
    
    docs = []
    docs.append("# API æ–‡æ¡£\n")
    
    for module_name in modules:
        module = importlib.import_module(module_name)
        docs.append(f"## {module_name}\n")
        
        # è·å–æ¨¡å—ä¸­çš„ç±»
        for name, obj in inspect.getmembers(module, inspect.isclass):
            if obj.__module__ == module_name:
                docs.append(f"### {name}\n")
                docs.append(f"{obj.__doc__ or 'æ— æ–‡æ¡£'}\n")
                
                # è·å–ç±»çš„æ–¹æ³•
                for method_name, method in inspect.getmembers(obj, inspect.ismethod):
                    if not method_name.startswith('_'):
                        signature = inspect.signature(method)
                        docs.append(f"#### {method_name}{signature}\n")
                        docs.append(f"{method.__doc__ or 'æ— æ–‡æ¡£'}\n")
        
        docs.append("\n")
    
    # ä¿å­˜æ–‡æ¡£
    with open('docs/API.md', 'w', encoding='utf-8') as f:
        f.write('\n'.join(docs))

if __name__ == "__main__":
    generate_api_docs()
```

è¿™ä¸ªå¼€å‘æŒ‡å—ä¸ºæ‚¨çš„MLPé¡¹ç›®æä¾›äº†å®Œæ•´çš„æ‰©å±•å¼€å‘æ¡†æ¶ï¼ŒåŒ…æ‹¬æ¶æ„åˆ†æã€æ‰©å±•æ–¹æ³•ã€å¼€å‘è§„èŒƒå’Œæœ€ä½³å®è·µã€‚é€šè¿‡éµå¾ªè¿™äº›æŒ‡å¯¼åŸåˆ™ï¼Œæ‚¨å¯ä»¥é«˜æ•ˆåœ°è¿›è¡ŒäºŒæ¬¡å¼€å‘å’ŒåŠŸèƒ½æ‰©å±•ã€‚